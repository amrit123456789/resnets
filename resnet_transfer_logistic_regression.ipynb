{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\g50\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "from keras import layers\n",
    "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\n",
    "from keras.models import Model, load_model\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import layer_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "import pydot\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.utils import plot_model\n",
    "#from resnets_utils import *\n",
    "from keras.initializers import glorot_uniform\n",
    "import scipy.misc\n",
    "from matplotlib.pyplot import imshow\n",
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "K.set_image_data_format('channels_last')\n",
    "K.set_learning_phase(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset_flower():\n",
    "    train_data_x = h5py.File('dataset/features.h5', \"r\")\n",
    "    train_data_y = h5py.File('dataset/labels.h5', \"r\")\n",
    "\n",
    "    #print(list(train_data_y.keys()))\n",
    "    features = np.array(train_data_x[\"dataset_1\"][:])\n",
    "    labels = np.array(train_data_y[\"dataset_1\"][:])\n",
    "    #print(train_set_x_orig.shape)\n",
    "    #print(train_set_y_orig.shape)\n",
    "    \n",
    "   \n",
    "    return features,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from shutil import copyfile\n",
    "class_names = [\"daffodil\", \"snowdrop\", \"lily_valley\", \"bluebell\", \"crocus\",\n",
    "              \"iris\", \"tigerlily\", \"tulip\", \"fritillary\", \"sunflower\", \n",
    "              \"daisy\", \"colts_foot\", \"dandelion\", \"cowslip\", \"buttercup\",\n",
    "              \"windflower\", \"pansy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder with label daffodil is complete\n",
      "Folder with label snowdrop is complete\n",
      "Folder with label lily_valley is complete\n",
      "Folder with label bluebell is complete\n",
      "Folder with label crocus is complete\n",
      "Folder with label iris is complete\n",
      "Folder with label tigerlily is complete\n",
      "Folder with label tulip is complete\n",
      "Folder with label fritillary is complete\n",
      "Folder with label sunflower is complete\n",
      "Folder with label daisy is complete\n",
      "Folder with label colts_foot is complete\n",
      "Folder with label dandelion is complete\n",
      "Folder with label cowslip is complete\n",
      "Folder with label buttercup is complete\n",
      "Folder with label windflower is complete\n",
      "Folder with label pansy is complete\n"
     ]
    }
   ],
   "source": [
    "class_limit = 17\n",
    "label = 0\n",
    "#X_train_orig = np.array([]).reshape((0,224,224,3))\n",
    "#Y_train_orig = np.array([]).reshape((1,0))\n",
    "X_train_orig = np.array([]).reshape((0,224,224,3))\n",
    "#Y_train_orig = np.array([]).reshape((1,0))\n",
    "Y_train_orig = []\n",
    "#print(X_train_orig.shape)\n",
    "train_path = \"dataset/train\"\n",
    "for x in range(class_limit):\n",
    "    curr_path = train_path + \"\\\\\" + class_names[label]\n",
    "    os.chdir(curr_path)\n",
    "    for image_path in glob.glob(curr_path + \"\\\\*.jpg\"):\n",
    "        img = image.load_img(image_path,target_size = (224,224,3))\n",
    "        x = image.img_to_array(img)\n",
    "        x = np.expand_dims(x,axis = 0)\n",
    "        x = preprocess_input(x)\n",
    "        X_train_orig = np.vstack((X_train_orig,x))\n",
    "        #print(X_train_orig.shape)\n",
    "        Y_train_orig.append(label)\n",
    "    print(\"Folder with label \"+str(class_names[label])+\" is complete\")\n",
    "    label+=1\n",
    "\n",
    "Y_train_orig = np.reshape(Y_train_orig,[1,len(Y_train_orig)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1190, 224, 224, 3)\n",
      "(1, 1190)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_orig.shape)\n",
    "print(Y_train_orig.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder with label daffodil is complete\n",
      "Folder with label snowdrop is complete\n",
      "Folder with label lily_valley is complete\n",
      "Folder with label bluebell is complete\n",
      "Folder with label crocus is complete\n",
      "Folder with label iris is complete\n",
      "Folder with label tigerlily is complete\n",
      "Folder with label tulip is complete\n",
      "Folder with label fritillary is complete\n",
      "Folder with label sunflower is complete\n",
      "Folder with label daisy is complete\n",
      "Folder with label colts_foot is complete\n",
      "Folder with label dandelion is complete\n",
      "Folder with label cowslip is complete\n",
      "Folder with label buttercup is complete\n",
      "Folder with label windflower is complete\n",
      "Folder with label pansy is complete\n"
     ]
    }
   ],
   "source": [
    "class_limit = 17\n",
    "label = 0\n",
    "X_test_orig = np.array([]).reshape((0,224,224,3))\n",
    "Y_test_orig = []\n",
    "\n",
    "test_path = \"dataset/validation\"\n",
    "for x in range(class_limit):\n",
    "    curr_path = test_path + \"\\\\\" + class_names[label]\n",
    "    os.chdir(curr_path)\n",
    "    for image_path in glob.glob(curr_path + \"\\\\*.jpg\"):\n",
    "        img = image.load_img(image_path,target_size = (224,224,3))\n",
    "        x = image.img_to_array(img)\n",
    "        x = np.expand_dims(x,axis = 0)\n",
    "        x = preprocess_input(x)\n",
    "        X_test_orig = np.vstack((X_test_orig,x))\n",
    "        #print(X_train_orig.shape)\n",
    "        Y_test_orig.append(label)\n",
    "    print(\"Folder with label \"+str(class_names[label])+\" is complete\")\n",
    "    label+=1\n",
    "\n",
    "Y_test_orig = np.reshape(Y_test_orig,[1,len(Y_test_orig)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(170, 224, 224, 3)\n",
      "(1, 170)\n"
     ]
    }
   ],
   "source": [
    "print(X_test_orig.shape)\n",
    "print(Y_test_orig.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_one_hot(A,C):\n",
    "    A = np.eye(C)[A.reshape(-1)].T\n",
    "    return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_test shape: (170, 17)\n"
     ]
    }
   ],
   "source": [
    "X_test = X_test_orig/255.\n",
    "\n",
    "Y_test = convert_to_one_hot(Y_test_orig, 17).T\n",
    "print (\"Y_test shape: \" + str(Y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "features,labels = load_dataset_flower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1360, 2048)\n",
      "(1360, 1)\n"
     ]
    }
   ],
   "source": [
    "print(features.shape)\n",
    "labels = np.reshape(labels,[labels.shape[0],1])\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "test_size = 170\n",
    "seed = 1\n",
    "(trainData, testData, trainLabels, testLabels) = train_test_split(features,\n",
    "                                                                  labels,\n",
    "                                                                  test_size=test_size,\n",
    "                                                                  random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1190, 2048)\n",
      "(170, 2048)\n",
      "(1190, 1)\n",
      "(170, 1)\n"
     ]
    }
   ],
   "source": [
    "print(trainData.shape)\n",
    "print(testData.shape)\n",
    "print(trainLabels.shape)\n",
    "print(testLabels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\g50\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=1, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#trainLabels = column_or_1d(trainLabels, warn=True)\n",
    "\n",
    "model = LogisticRegression(random_state=seed)\n",
    "model.fit(trainData, trainLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58.82352941176471\n",
      "92.3529411764706\n"
     ]
    }
   ],
   "source": [
    "rank_1 = 0\n",
    "rank_5 = 0\n",
    "\n",
    "# loop over test data\n",
    "for (label, features) in zip(testLabels, testData):\n",
    "    # predict the probability of each class label and\n",
    "    # take the top-5 class labels\n",
    "    predictions = model.predict_proba(np.atleast_2d(features))[0]\n",
    "    predictions = np.argsort(predictions)[::-1][:5]\n",
    "    \n",
    "    # rank-1 prediction increment\n",
    "    if label == predictions[0]:\n",
    "        rank_1 += 1\n",
    "\n",
    "    #rank-5 prediction increment\n",
    "    if label in predictions:\n",
    "        rank_5 += 1\n",
    "\n",
    "# convert accuracies to percentages\n",
    "rank_1 = (rank_1 / float(len(testLabels))) * 100\n",
    "rank_5 = (rank_5 / float(len(testLabels))) * 100\n",
    "print(rank_1)\n",
    "print(rank_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.17      0.14      0.15         7\n",
      "          1       0.69      0.75      0.72        12\n",
      "          2       0.50      0.77      0.61        13\n",
      "          3       0.44      0.31      0.36        13\n",
      "          4       0.25      0.29      0.27         7\n",
      "          5       0.50      0.38      0.43         8\n",
      "          6       1.00      0.80      0.89         5\n",
      "          7       0.62      0.42      0.50        12\n",
      "          8       0.46      0.67      0.55         9\n",
      "          9       0.73      0.80      0.76        10\n",
      "         10       0.86      0.67      0.75         9\n",
      "         11       0.33      0.33      0.33         6\n",
      "         12       0.65      0.79      0.71        14\n",
      "         13       0.83      0.71      0.77        14\n",
      "         14       0.78      0.58      0.67        12\n",
      "         15       0.30      0.33      0.32         9\n",
      "         16       0.82      0.90      0.86        10\n",
      "\n",
      "avg / total       0.60      0.59      0.59       170\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "preds = model.predict(testData)\n",
    "print(format(classification_report(testLabels, preds)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
